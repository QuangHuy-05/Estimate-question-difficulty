{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29508867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\quang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.55.4)\n",
      "Requirement already satisfied: underthesea in c:\\users\\quang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (6.8.4)\n",
      "Requirement already satisfied: torch in c:\\users\\quang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\quang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\quang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
      "ERROR: No matching distribution found for json\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers underthesea torch numpy pandas json sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d16af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quang\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\NCKH\\estimate_question_difficulty\\Embedding\\Output_ws\\questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b60fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, qid=None, subject=None, max_len=512):\n",
    "    if not text.strip():\n",
    "        return np.zeros(768)\n",
    "    try:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # CLS\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi embedding câu hỏi id={qid}, môn={subject}\")\n",
    "        return np.zeros(768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a1aac",
   "metadata": {},
   "source": [
    "Đoạn code dưới đây sẽ trích xuất ra độ nhiễu của giữa từng options so với answer:   \n",
    "- **mean_sim**: trung bình cosine similarity giữa đáp án đúng và các đáp án sai. Càng cao càng giống\n",
    "- **max_sim**: giá trị similarity lớn nhất giữa đáp án đúng và các đáp án sai  \n",
    "- **min_sim**: giá trị similarity nhỏ nhất  \n",
    "- **std_sim**: độ lệch chuẩn similarity. Nếu std_sim cao → có option gần đúng và option rất xa đúng cùng tồn tại, câu hỏi có thể gây phân vân; nếu thấp → tất cả option sai đều gần như cùng mức so với đáp án đúng.\n",
    "- **range_sim**: khoảng cách giữa max_sim và min_sim. một số option rất gần đáp án đúng, số khác rất xa, gây phân tán độ khó.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "566c136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi khi embedding câu hỏi id=59, môn=Văn_học\n",
      "Lỗi khi embedding câu hỏi id=60, môn=Văn_học\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "ids = []\n",
    "csv_rows = []\n",
    "\n",
    "for item in data:\n",
    "    question = item[\"question\"]\n",
    "    options = item[\"options\"]\n",
    "    answer_key = item[\"answer\"]\n",
    "\n",
    "    try:\n",
    "        answer_index = options.index(answer_key)\n",
    "    except ValueError:\n",
    "        print(f\"Câu hỏi {item['id']} không có answer trong options\")\n",
    "        continue \n",
    "\n",
    "    emb_answer = get_embedding(question + \" \" + options[answer_index], qid=item[\"id\"], subject=item[\"subject\"])\n",
    "    if emb_answer is None or not emb_answer.any():\n",
    "        continue\n",
    "\n",
    "    wrong_embs = [\n",
    "        get_embedding(question + \" \" + opt, qid=item[\"id\"], subject=item[\"subject\"])\n",
    "        for i, opt in enumerate(options) if i != answer_index\n",
    "    ]\n",
    "    sims = [cosine_similarity([emb_answer], [emb])[0][0] for emb in wrong_embs]\n",
    "\n",
    "    if len(sims) > 0:\n",
    "        mean_sim = float(np.mean(sims))\n",
    "        max_sim = float(np.max(sims))\n",
    "        min_sim = float(np.min(sims))\n",
    "        std_sim = float(np.std(sims))\n",
    "        range_sim = max_sim - min_sim\n",
    "    else:\n",
    "        mean_sim = max_sim = min_sim = std_sim = range_sim = 0.0\n",
    "\n",
    "    features.append([mean_sim, max_sim, min_sim, std_sim, range_sim])\n",
    "    ids.append(item[\"id\"])\n",
    "    csv_rows.append({\n",
    "        \"id\": item[\"id\"],\n",
    "        \"question\": item[\"question\"],\n",
    "        \"answer\": answer_key,\n",
    "        \"mean_sim\": mean_sim,\n",
    "        \"max_sim\": max_sim,\n",
    "        \"min_sim\": min_sim,\n",
    "        \"std_sim\": std_sim,\n",
    "        \"range_sim\": range_sim\n",
    "    })\n",
    "features = np.array(features) \n",
    "ids = np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c001d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu noise_features.npy và ids.npy\n",
      "Đã lưu CSV kiểm tra: D:\\NCKH\\estimate_question_difficulty\\Embedding\\Output_features\\noise_features.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== 5. Lưu numpy =====\n",
    "output_dir = r\"D:\\NCKH\\estimate_question_difficulty\\Embedding\\Output_features\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "features = np.array(features)\n",
    "ids = np.array(ids)\n",
    "\n",
    "np.save(os.path.join(output_dir, \"noise_features.npy\"), features)\n",
    "np.save(os.path.join(output_dir, \"ids.npy\"), ids)\n",
    "print(\"Đã lưu noise_features.npy và ids.npy\")\n",
    "\n",
    "# ===== 6. Lưu CSV =====\n",
    "csv_path = os.path.join(output_dir, \"noise_features.csv\")\n",
    "with open(csv_path, \"w\", newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=csv_rows[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(csv_rows)\n",
    "\n",
    "print(\"Đã lưu CSV kiểm tra:\", csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
