{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b416ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  √ó python setup.py egg_info did not run successfully.\n",
      "  ‚îÇ exit code: 1\n",
      "  ‚ï∞‚îÄ> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "√ó Encountered error while generating package metadata.\n",
      "‚ï∞‚îÄ> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn joblib imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc709ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib  # ƒë·ªÉ l∆∞u model\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c6421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"D:\\NCKH\\estimate_question_difficulty\\training\\merged.csv\")\n",
    "X = df.drop(columns=[\"id\", \"Bloom_Label\"])\n",
    "y = df[\"Bloom_Label\"]\n",
    "# ‚öñÔ∏è C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)  # k_neighbors=1 v√¨ c√≥ l·ªõp ch·ªâ c√≥ 3 m·∫´u\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# # Ki·ªÉm tra s·ªë l∆∞·ª£ng m·∫´u trong t·ª´ng class\n",
    "# class_counts = y.value_counts()\n",
    "# print(\"üìä S·ªë l∆∞·ª£ng m·∫´u trong t·ª´ng class:\\n\", class_counts)\n",
    "\n",
    "# # Ph√°t hi·ªán class n√†o c√≥ < 2 m·∫´u\n",
    "# rare_classes = class_counts[class_counts < 2]\n",
    "# if not rare_classes.empty:\n",
    "#     print(\"\\n‚ö†Ô∏è C√°c l·ªõp c√≥ √≠t h∆°n 2 m·∫´u, c√≥ th·ªÉ g√¢y l·ªói khi stratify:\")\n",
    "#     print(rare_classes)\n",
    "\n",
    "# # B∆∞·ªõc 1: train (70%) + temp (30%)\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "#     X, y,\n",
    "#     test_size=0.3,\n",
    "#     stratify=y,        # gi·ªØ t·ª∑ l·ªá class trong train\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # B∆∞·ªõc 2: t·ª´ temp (30%) chia th√†nh val (20%) v√† test (10%)\n",
    "# # => test_size = 10 / (20+10) = 1/3\n",
    "# try:\n",
    "#     X_val, X_test, y_val, y_test = train_test_split(\n",
    "#         X_temp, y_temp,\n",
    "#         test_size=1/3,\n",
    "#         stratify=y_temp,   # c√≥ th·ªÉ l·ªói n·∫øu class qu√° √≠t\n",
    "#         random_state=42\n",
    "#     )\n",
    "# except ValueError:\n",
    "#     print(\"\\n‚ö†Ô∏è C√≥ l·ªõp qu√° √≠t m·∫´u => b·ªè stratify khi chia val/test.\")\n",
    "#     X_val, X_test, y_val, y_test = train_test_split(\n",
    "#         X_temp, y_temp,\n",
    "#         test_size=1/3,\n",
    "#         random_state=42\n",
    "#     )\n",
    "\n",
    "# print(\"\\n‚úÖ K√≠ch th∆∞·ªõc t·∫≠p d·ªØ li·ªáu:\")\n",
    "# print(\"Train:\", len(X_train))\n",
    "# print(\"Validation:\", len(X_val))\n",
    "# print(\"Test:\", len(X_test))\n",
    "\n",
    "# Tr·ªçng s·ªë cho t·ª´ng feature\n",
    "weights = {\n",
    "    \"mean_sim\": 2.0,\n",
    "    \"max_sim\": 2.0,\n",
    "    \"min_sim\": 2.0,\n",
    "    \"std_sim\": 2.0,\n",
    "    \"range_sim\": 2.0,\n",
    "    \"sentence_length\": 1,\n",
    "    \"avg_word_length\": 1,\n",
    "    \"num_clauses\": 1.5,\n",
    "    \"num_punct\": 0,\n",
    "    \"num_nouns\": 1.2,\n",
    "    \"num_verbs\": 1.2,\n",
    "    \"num_adjs\": 1.2,\n",
    "    \"num_lit_terms\": 1.5,\n",
    "    \"perplexity\": 2.0\n",
    "}\n",
    "\n",
    "# Nh√¢n tr·ªçng s·ªë\n",
    "for col, w in weights.items():\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col] * w\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# B∆∞·ªõc 2: t·ª´ temp (30%) chia th√†nh val (20%) v√† test (10%)\n",
    "# t·ªâ l·ªá test_size = 10 / (20+10) = 1/3\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=1/3, random_state=42\n",
    ")\n",
    "# clf = RandomForestClassifier(\n",
    "#     n_estimators=200,   # s·ªë c√¢y (c√†ng nhi·ªÅu c√†ng ch√≠nh x√°c nh∆∞ng ch·∫≠m)\n",
    "#     max_depth=None,    # cho ph√©p c√¢y ph√°t tri·ªÉn ƒë·∫ßy ƒë·ªß\n",
    "#     random_state=42\n",
    "#     ,oob_score=True\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bae7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8af0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªãnh nghƒ©a c√°c tham s·ªë c·∫ßn th·ª≠\n",
    "param_grid = {\n",
    "    \"n_estimators\": [500, 600,700],         # s·ªë c√¢y\n",
    "    \"max_depth\": [None, 10, 20, 30],         # ƒë·ªô s√¢u t·ªëi ƒëa\n",
    "    \"min_samples_split\": [4, 5, 7],         # s·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ split\n",
    "    \"max_features\": [\"sqrt\", \"log2\",\"none\"],        # s·ªë feature d√πng khi split\n",
    "    \"class_weight\": [None, \"balanced\"]       # c√¢n b·∫±ng d·ªØ li·ªáu hay kh√¥ng\n",
    "}\n",
    "rf = RandomForestClassifier(random_state= 20)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv= 10,               # 5-fold cross-validation\n",
    "    n_jobs=-1,          # ch·∫°y song song nhi·ªÅu CPU core\n",
    "    verbose=2,\n",
    "    scoring=\"f1_macro\"  # c√≥ th·ªÉ ƒë·ªïi sang \"f1_macro\" n·∫øu d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# D√πng model t·ªët nh·∫•t ƒë·ªÉ test\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nB√°o c√°o ph√¢n lo·∫°i:\\n\", classification_report(y_test, y_pred))\n",
    "# clf.fit(X_train, y_train)\n",
    "# # D·ª± ƒëo√°n\n",
    "# y_pred = clf.predict(X_test)\n",
    "# # ƒê√°nh gi√° m√¥ h√¨nh\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"\\nB√°o c√°o ph√¢n lo·∫°i:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "joblib.dump(best_model, r\"D:\\NCKH\\estimate_question_difficulty\\training\\random_forest_best.pkl\")\n",
    "print(\"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh v√†o random_forest_best.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10392552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# ƒê√°nh gi√° m√¥ h√¨nh v·ªõi 10-fold CV\n",
    "cv_results = cross_validate(\n",
    "    best_model, \n",
    "    X, y, \n",
    "    cv=10, \n",
    "    scoring=[\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\"],\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# In k·∫øt qu·∫£ trung b√¨nh + ƒë·ªô l·ªách chu·∫©n\n",
    "print(\"\\n--- ƒê√°nh gi√° b·∫±ng 10-fold Cross-Validation ---\")\n",
    "for metric in [\"train_accuracy\", \"test_accuracy\", \n",
    "               \"train_precision_macro\", \"test_precision_macro\", \n",
    "               \"train_recall_macro\", \"test_recall_macro\", \n",
    "               \"train_f1_macro\", \"test_f1_macro\"]:\n",
    "    mean_score = np.mean(cv_results[metric])\n",
    "    std_score = np.std(cv_results[metric])\n",
    "    print(f\"{metric}: {mean_score:.4f} ¬± {std_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
