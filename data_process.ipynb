{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899851ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3239 questions from Văn học\n",
      "Loaded 670 questions from sử\n",
      "Loaded 838 questions from địa\n",
      "Loaded 72 questions from anh\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "from vncorenlp import VnCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d6893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_answer_format(ans):\n",
    "    if not isinstance(ans, str):\n",
    "        return ans\n",
    "    # Thêm dấu chấm + space nếu thiếu sau A/B/C/D\n",
    "    ans = re.sub(r\"^([A-D])[\\.\\s]*\", r\"\\1. \", ans.strip())\n",
    "    # Bỏ khoảng trắng thừa\n",
    "    ans = re.sub(r\"\\s+\", \" \", ans).strip()\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d30f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text):\n",
    "    \"\"\"\n",
    "    Simple Vietnamese tokenization function\n",
    "    Args:\n",
    "        text (str): Input text to tokenize\n",
    "    Returns:\n",
    "        str: Tokenized text with spaces between words\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Tách từ đơn giản bằng khoảng trắng\n",
    "    words = text.split()\n",
    "    \n",
    "    # Tách số và chữ\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # Tách số và chữ\n",
    "        word = re.sub(r'([A-Za-z])([0-9])', r'\\1 \\2', word)\n",
    "        word = re.sub(r'([0-9])([A-Za-z])', r'\\1 \\2', word)\n",
    "        # Tách chữ hoa\n",
    "        word = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', word)\n",
    "        processed_words.append(word)\n",
    "    \n",
    "    return ' '.join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Chuẩn hóa Unicode (xử lý dấu tiếng Việt)\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "    # Bỏ xuống dòng, tab, khoảng trắng thừa\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Bỏ ký tự đặc biệt không cần thiết\n",
    "    text = re.sub(r\"[^\\w\\sÀ-ỹ]\", \"\", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0260dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_question(qa_pairs, all_data):\n",
    "#     for subject, data in all_data.items():\n",
    "#         for item in data:\n",
    "#             if \"question\" in item and \"answers\" in item:\n",
    "#                 clean_q = clean_text(item[\"question\"])\n",
    "#                 # Xử lý đáp án: vừa clean_text vừa fix format\n",
    "#                 clean_ans = [fix_answer_format(clean_text(ans)) for ans in item[\"answers\"]]\n",
    "#                 correct_ans = item.get(\"correct_answer\")\n",
    "#                 explanation = clean_text(item.get(\"explanation\", \"\"))\n",
    "\n",
    "#                 if clean_q and clean_ans:  # chỉ lấy nếu có cả câu hỏi và câu trả lời\n",
    "#                     qa_pairs.append({\n",
    "#                         \"subject\": subject,\n",
    "#                         \"question\": clean_q,\n",
    "#                         \"answers\": clean_ans,\n",
    "#                         \"correct_answer\": correct_ans,\n",
    "#                         \"explanation\": explanation if explanation else None\n",
    "#                     })\n",
    "\n",
    "def clean_question(qa_pairs, all_data):\n",
    "    for subject, data in all_data.items():\n",
    "        for idx, item in enumerate(data):\n",
    "            # Nếu thiếu field bắt buộc thì bỏ qua\n",
    "            if not item.get(\"question\") or not item.get(\"answers\"):\n",
    "                print(f\"Bỏ câu {idx} trong {subject}: thiếu question/answers\")\n",
    "                continue  \n",
    "\n",
    "            # Nếu bất kỳ đáp án nào là None thì bỏ qua luôn\n",
    "            if any(ans is None for ans in item[\"answers\"]):\n",
    "                print(f\"Bỏ câu {idx} trong {subject}: có đáp án null\")\n",
    "                continue  \n",
    "\n",
    "            try:\n",
    "                clean_q = clean_text(item[\"question\"])\n",
    "                clean_ans = [fix_answer_format(clean_text(str(ans))) for ans in item[\"answers\"]]\n",
    "\n",
    "                # Lấy correct answer\n",
    "                correct_ans_label = item.get(\"correct_answer\")\n",
    "                correct_ans_full = None\n",
    "                if correct_ans_label:\n",
    "                    correct_ans_label = str(correct_ans_label).strip().upper()\n",
    "                    # Ánh xạ A/B/C/D -> đáp án\n",
    "                    label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "                    if correct_ans_label in label_map and label_map[correct_ans_label] < len(clean_ans):\n",
    "                        ans_text = clean_ans[label_map[correct_ans_label]]\n",
    "                        # Nếu ans_text đã bắt đầu bằng \"B. \" thì giữ nguyên,\n",
    "                        # nếu chưa thì thêm \"B. \" vào trước\n",
    "                        if re.match(rf\"^{correct_ans_label}\\.\\s\", ans_text):\n",
    "                            correct_ans_full = ans_text\n",
    "                        else:\n",
    "                            correct_ans_full = f\"{correct_ans_label}. {ans_text}\"\n",
    "                    else:\n",
    "                        correct_ans_full = correct_ans_label\n",
    "\n",
    "                explanation = clean_text(item.get(\"explanation\", \"\"))\n",
    "\n",
    "                qa_pairs.append({\n",
    "                    \"subject\": subject,\n",
    "                    \"question\": clean_q,\n",
    "                    \"answers\": clean_ans,\n",
    "                    \"correct_answer\": correct_ans_full,\n",
    "                    \"explanation\": explanation if explanation else None\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi xử lý câu {idx} trong {subject}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de012b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách từ\n",
    "\n",
    "def clean_word(processed_qa, qa_pairs):\n",
    "    for qa in qa_pairs:\n",
    "        processed_qa.append({\n",
    "            \"subject\": qa[\"subject\"],\n",
    "            \"question\": simple_tokenize(qa[\"question\"]),\n",
    "            \"answers\": [simple_tokenize(ans) for ans in qa[\"answers\"]],\n",
    "            \"correct_answer\": qa[\"correct_answer\"],\n",
    "            \"explanation\": simple_tokenize(qa[\"explanation\"]) if qa[\"explanation\"] else None\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e86faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_processed(processed_qa):\n",
    "    # Lưu kết quả vào file\n",
    "    if not os.path.exists(\"data_processed\"):\n",
    "        os.makedirs(\"data_processed\")\n",
    "\n",
    "    questions_by_subject = {}\n",
    "    for qa in processed_qa:\n",
    "        subject = qa['subject']\n",
    "        if subject not in questions_by_subject:\n",
    "            questions_by_subject[subject] = []\n",
    "        questions_by_subject[subject].append(qa)\n",
    "\n",
    "    for subject, questions in questions_by_subject.items():\n",
    "        output_file = f\"data_processed/{subject}_processed.txt\"\n",
    "        \n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Tổng số câu hỏi môn {subject}: {len(questions)}\\n\\n\")\n",
    "            \n",
    "            for i, qa in enumerate(questions, 1):\n",
    "                f.write(f\"Câu {i}:\\n\")\n",
    "                f.write(f\"Môn: {qa['subject']}\\n\")\n",
    "                f.write(f\"Câu hỏi: {qa['question']}\\n\")\n",
    "                f.write(\"Các đáp án:\\n\")\n",
    "                for j, ans in enumerate(qa['answers'], 1):\n",
    "                    f.write(f\"  {ans}\\n\")\n",
    "                f.write(f\"Đáp án đúng: {qa['correct_answer']}\\n\")\n",
    "                if qa['explanation']:\n",
    "                    f.write(f\"Giải thích: {qa['explanation']}\\n\")\n",
    "                f.write(\"\\n\" + \"-\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        print(f\"\\nĐã xử lý và lưu {len(questions)} câu hỏi môn {subject} vào file '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
