{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899851ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3239 questions from văn\n",
      "Loaded 670 questions from sử\n",
      "Loaded 838 questions from địa\n",
      "Loaded 72 questions from anh\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "from vncorenlp import VnCoreNLP\n",
    "\n",
    "subject_files = {\n",
    "    \"văn\": \"output/văn.json\",\n",
    "    \"sử\": \"output/sử.json\",\n",
    "    \"địa\": \"output/địa.json\",\n",
    "    \"anh\": \"output/anh_văn.json\"\n",
    "}\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for subject, file_path in subject_files.items():\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            all_data[subject] = json.load(f)\n",
    "        print(f\"Loaded {len(all_data[subject])} questions from {subject}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found - {file_path}\")\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d30f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text):\n",
    "    \"\"\"\n",
    "    Simple Vietnamese tokenization function\n",
    "    Args:\n",
    "        text (str): Input text to tokenize\n",
    "    Returns:\n",
    "        str: Tokenized text with spaces between words\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Tách từ đơn giản bằng khoảng trắng\n",
    "    words = text.split()\n",
    "    \n",
    "    # Tách số và chữ\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # Tách số và chữ\n",
    "        word = re.sub(r'([A-Za-z])([0-9])', r'\\1 \\2', word)\n",
    "        word = re.sub(r'([0-9])([A-Za-z])', r'\\1 \\2', word)\n",
    "        # Tách chữ hoa\n",
    "        word = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', word)\n",
    "        processed_words.append(word)\n",
    "    \n",
    "    return ' '.join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Chuẩn hóa Unicode (xử lý dấu tiếng Việt)\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "    # Bỏ xuống dòng, tab, khoảng trắng thừa\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Bỏ ký tự đặc biệt không cần thiết\n",
    "    text = re.sub(r\"[^\\w\\sÀ-ỹ]\", \"\", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0260dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy và làm sạch câu hỏi\n",
    "qa_pairs = []\n",
    "for subject, data in all_data.items():\n",
    "    for item in data:\n",
    "        if \"question\" in item and \"answers\" in item:\n",
    "            clean_q = clean_text(item[\"question\"])\n",
    "            clean_ans = [clean_text(ans) for ans in item[\"answers\"]]\n",
    "            correct_ans = item.get(\"correct_answer\")\n",
    "            explanation = clean_text(item.get(\"explanation\", \"\"))\n",
    "            \n",
    "            if clean_q and clean_ans:  # chỉ lấy nếu có cả câu hỏi và câu trả lời\n",
    "                qa_pairs.append({\n",
    "                    \"subject\": subject,\n",
    "                    \"question\": clean_q,\n",
    "                    \"answers\": clean_ans,\n",
    "                    \"correct_answer\": correct_ans,\n",
    "                    \"explanation\": explanation if explanation else None\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de012b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách từ\n",
    "processed_qa = []\n",
    "for qa in qa_pairs:\n",
    "    processed_qa.append({\n",
    "        \"subject\": qa[\"subject\"],\n",
    "        \"question\": simple_tokenize(qa[\"question\"]),\n",
    "        \"answers\": [simple_tokenize(ans) for ans in qa[\"answers\"]],\n",
    "        \"correct_answer\": qa[\"correct_answer\"],\n",
    "        \"explanation\": simple_tokenize(qa[\"explanation\"]) if qa[\"explanation\"] else None\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e86faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã xử lý và lưu 3210 câu hỏi môn văn vào file 'data_processed/văn_processed.txt'\n",
      "\n",
      "Đã xử lý và lưu 670 câu hỏi môn sử vào file 'data_processed/sử_processed.txt'\n",
      "\n",
      "Đã xử lý và lưu 834 câu hỏi môn địa vào file 'data_processed/địa_processed.txt'\n",
      "\n",
      "Đã xử lý và lưu 35 câu hỏi môn anh vào file 'data_processed/anh_processed.txt'\n"
     ]
    }
   ],
   "source": [
    "# Lưu kết quả vào file\n",
    "if not os.path.exists(\"data_processed\"):\n",
    "    os.makedirs(\"data_processed\")\n",
    "\n",
    "questions_by_subject = {}\n",
    "for qa in processed_qa:\n",
    "    subject = qa['subject']\n",
    "    if subject not in questions_by_subject:\n",
    "        questions_by_subject[subject] = []\n",
    "    questions_by_subject[subject].append(qa)\n",
    "\n",
    "for subject, questions in questions_by_subject.items():\n",
    "    output_file = f\"data_processed/{subject}_processed.txt\"\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Tổng số câu hỏi môn {subject}: {len(questions)}\\n\\n\")\n",
    "        \n",
    "        for i, qa in enumerate(questions, 1):\n",
    "            f.write(f\"Câu {i}:\\n\")\n",
    "            f.write(f\"Câu hỏi: {qa['question']}\\n\")\n",
    "            f.write(\"Các đáp án:\\n\")\n",
    "            for j, ans in enumerate(qa['answers'], 1):\n",
    "                f.write(f\"  {j}. {ans}\\n\")\n",
    "            f.write(f\"Đáp án đúng: {qa['correct_answer']}\\n\")\n",
    "            if qa['explanation']:\n",
    "                f.write(f\"Giải thích: {qa['explanation']}\\n\")\n",
    "            f.write(\"\\n\" + \"-\"*50 + \"\\n\\n\")\n",
    "    \n",
    "    print(f\"\\nĐã xử lý và lưu {len(questions)} câu hỏi môn {subject} vào file '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
